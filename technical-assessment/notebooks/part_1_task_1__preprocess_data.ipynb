{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e39590e",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c3f8e",
   "metadata": {},
   "source": [
    "### Task 1 - Examine the sample data, determine which rows don't follow the business rules and clean the data.\n",
    "\n",
    "##### Detect and clean rows that break the 5 business rules:\n",
    "\n",
    "1. The players are not allowed to make any transactions before they are KYC verified.\n",
    "2. Multiple players can use the same affiliate code, but each code redeemed should match 1:1 to the\n",
    "player with the affiliate ID.\n",
    "3. An affiliate redeemed must be linked to a player.\n",
    "4. Players may or may not use an affiliate code to join.\n",
    "5. The IDs of all tables are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170a9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Timedelta\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "# It ensures that any random operations produce the same results each time the code is run.\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a469fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "players: (11, 6)\n",
      "affiliates: (10, 4)\n",
      "transactions: (10, 5)\n"
     ]
    }
   ],
   "source": [
    "# Define root path\n",
    "ROOT = '/Users/augustocardosoagostini/Desktop/Outros Documentos/Documentos Gerais/trainings/dbt_airflow/project/analytical-assessment/technical-assessment/data'\n",
    "\n",
    "# Load data\n",
    "df_players = pd.read_csv(f\"{ROOT}/Sample_data_-_Technical_Interview_-_players.csv\")\n",
    "df_affiliates = pd.read_csv(f\"{ROOT}/Sample_data_-_Technical_Interview_-_affiliates.csv\")\n",
    "df_transactions = pd.read_csv(f\"{ROOT}/Sample_data_-_Technical_Interview_-_transactions.csv\")\n",
    "\n",
    "# Check the shape of the dataframes\n",
    "print(\"players:\", df_players.shape)\n",
    "print(\"affiliates:\", df_affiliates.shape)\n",
    "print(\"transactions:\", df_transactions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe5b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep originals untouched\n",
    "df_players_clean = df_players.copy()\n",
    "df_affiliates_clean = df_affiliates.copy()\n",
    "df_transactions_clean = df_transactions.copy()\n",
    "\n",
    "# Standardize column names\n",
    "df_players_clean.columns = [col.strip().lower() for col in df_players_clean.columns]\n",
    "df_affiliates_clean.columns = [col.strip().lower() for col in df_affiliates_clean.columns]\n",
    "df_transactions_clean.columns = [col.strip().lower() for col in df_transactions_clean.columns]\n",
    "\n",
    "# Convert timestamp columns to datetimes (errors='coerce' keeps invalid rows as NaT)\n",
    "df_players_clean['created_at'] = pd.to_datetime(df_players_clean['created_at'], errors='coerce')\n",
    "df_players_clean['updated_at'] = pd.to_datetime(df_players_clean['updated_at'], errors='coerce')\n",
    "df_affiliates_clean['redeemed_at'] = pd.to_datetime(df_affiliates_clean['redeemed_at'], errors='coerce')\n",
    "df_transactions_clean['timestamp'] = pd.to_datetime(df_transactions_clean['timestamp'], errors='coerce')\n",
    "\n",
    "# Normalize affiliate_id column to nullable integer (pandas Int64)\n",
    "df_players_clean['affiliate_id'] = df_players_clean['affiliate_id'].astype('Int64')\n",
    "\n",
    "# Prepare exceptions log list-of-dfs\n",
    "exceptions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a2cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes after deduplication for players, affiliates, and transactions:\n",
      "(10, 6) (10, 4) (10, 5)\n"
     ]
    }
   ],
   "source": [
    "# Rule 5: IDs of all tables are unique\n",
    "\n",
    "# transactions.id unique\n",
    "tx_dup_ids = df_transactions_clean[df_transactions_clean['id'].duplicated(keep=False)].sort_values('id')\n",
    "if not tx_dup_ids.empty:\n",
    "    tx_dup_ids['reason'] = 'duplicate_transaction_id'\n",
    "    exceptions.append(tx_dup_ids)\n",
    "    # Keep the latest by timestamp for duplicates\n",
    "    df_transactions_clean = df_transactions_clean.sort_values('timestamp').drop_duplicates('id', keep='last').reset_index(drop=True)\n",
    "\n",
    "# players.id unique\n",
    "player_dup = df_players_clean[df_players_clean['id'].duplicated(keep=False)].sort_values(['id','updated_at'])\n",
    "if not player_dup.empty:\n",
    "    player_dup['reason'] = 'duplicate_player_id'\n",
    "    exceptions.append(player_dup)\n",
    "    # Business rule: keep the most recently updated record\n",
    "    df_players_clean = df_players_clean.sort_values('updated_at').drop_duplicates('id', keep='last').reset_index(drop=True)\n",
    "\n",
    "# affiliates.id unique\n",
    "aff_dup = df_affiliates_clean[df_affiliates_clean['id'].duplicated(keep=False)]\n",
    "if not aff_dup.empty:\n",
    "    aff_dup['reason'] = 'duplicate_affiliate_id'\n",
    "    exceptions.append(aff_dup)\n",
    "    df_affiliates_clean = df_affiliates_clean.drop_duplicates('id', keep='last').reset_index(drop=True)\n",
    "\n",
    "print(\"Shapes after deduplication for players, affiliates, and transactions:\")\n",
    "print(df_players_clean.shape, df_affiliates_clean.shape, df_transactions_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb5fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 1: No transactions before player is KYC verified\n",
    "\n",
    "# Join transaction -> player.created_at and player.is_kyc_approved\n",
    "player_meta = df_players_clean[['id','is_kyc_approved','created_at']].rename(columns={'id':'player_id','created_at':'player_created_at','is_kyc_approved':'player_is_kyc'})\n",
    "tx_with_meta = df_transactions_clean.merge(player_meta, on='player_id', how='left', indicator=True)\n",
    "\n",
    "# 1a: transactions referencing missing players -> violation of rule 3 (affiliate redeemed must be linked to player)\n",
    "missing_player_tx = tx_with_meta[tx_with_meta['_merge']=='left_only'].copy()\n",
    "if not missing_player_tx.empty:\n",
    "    missing_player_tx['reason'] = 'tx_missing_player'\n",
    "    exceptions.append(missing_player_tx)\n",
    "\n",
    "# 1b: transactions where player exists but is not KYC verified -> violate rule 1\n",
    "tx_by_unkyc = tx_with_meta[(tx_with_meta['_merge']=='both') & (tx_with_meta['player_is_kyc']==False)].copy()\n",
    "if not tx_by_unkyc.empty:\n",
    "    tx_by_unkyc['reason'] = 'tx_by_unkyc_player'\n",
    "    exceptions.append(tx_by_unkyc)\n",
    "\n",
    "# 1c: transactions with timestamp < player's created_at (player couldn't have trans before account creation)\n",
    "tx_before_created = tx_with_meta[(tx_with_meta['_merge']=='both') & (tx_with_meta['timestamp'] < tx_with_meta['player_created_at'])].copy()\n",
    "if not tx_before_created.empty:\n",
    "    tx_before_created['reason'] = 'tx_before_player_creation'\n",
    "    exceptions.append(tx_before_created)\n",
    "\n",
    "\n",
    "# Conservative cleaning choices:\n",
    "# - Drop transactions referencing missing players (assume we cannot assign it to an invented player). -> remove from df_transactions_clean.\n",
    "# - Drop transactions by not KYC verified players (business rule forbids it). Put them into exceptions and remove.\n",
    "# - Drop transactions before player creation (assume data error, cannot fix). Put them into exceptions and remove.\n",
    "\n",
    "# Implementing changes:\n",
    "# Remove all transactions that break these rules from the clean dataset\n",
    "bad_tx_ids = set(missing_player_tx['id'].tolist()) \\\n",
    "           | set(tx_by_unkyc['id'].tolist()) \\\n",
    "           | set(tx_before_created['id'].tolist())\n",
    "\n",
    "df_transactions_clean = df_transactions_clean[~df_transactions_clean['id'].isin(bad_tx_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640705e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules 2 and 3 (affiliate redemption logic)\n",
    "\n",
    "# Rules explanation:\n",
    "# - Multiple players can share the same affiliate code.\n",
    "# - BUT, if an affiliate has redeemed_at NOT NULL, it must be linked to exactly ONE player.\n",
    "# - That is, if multiple players reference a redeemed affiliate, \n",
    "#   or a redeemed affiliate is not referenced by any player, that affiliate record violates the rules.\n",
    "\n",
    "# Count how many players reference each affiliate\n",
    "player_aff_counts = df_players_clean.groupby('affiliate_id')['id'].count().rename('player_count')\n",
    "\n",
    "# Merge into affiliates\n",
    "aff_with_counts = df_affiliates_clean.merge(player_aff_counts, how='left', left_on='id', right_on='affiliate_id').fillna({'player_count': 0})\n",
    "\n",
    "# Identify violations\n",
    "viol_redeemed_no_player = aff_with_counts[aff_with_counts['redeemed_at'].notna() & (aff_with_counts['player_count'] == 0)].copy()\n",
    "viol_redeemed_multi_players = aff_with_counts[aff_with_counts['redeemed_at'].notna() & (aff_with_counts['player_count'] > 1)].copy()\n",
    "\n",
    "if not viol_redeemed_no_player.empty:\n",
    "    viol_redeemed_no_player['reason'] = 'redeemed_affiliate_not_linked_to_player'\n",
    "    exceptions.append(viol_redeemed_no_player)\n",
    "\n",
    "if not viol_redeemed_multi_players.empty:\n",
    "    viol_redeemed_multi_players['reason'] = 'redeemed_affiliate_has_multiple_players'\n",
    "    exceptions.append(viol_redeemed_multi_players)\n",
    "\n",
    "# Null out redeemed_at if the redemption is invalid (no player or multiple players)\n",
    "bad_aff_ids = set(viol_redeemed_no_player['id']).union(set(viol_redeemed_multi_players['id']))\n",
    "df_affiliates_clean.loc[df_affiliates_clean['id'].isin(bad_aff_ids), 'redeemed_at'] = pd.NaT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf0005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 4: players may or may not use affiliate code\n",
    "\n",
    "# It's allowed to have a player's affiliate_id missing (we only ensure affiliate_id values really exist in affiliates)\n",
    "missing_aff_ids = set(df_players_clean['affiliate_id'].dropna().astype(int)) - set(df_affiliates_clean['id'].astype(int))\n",
    "if missing_aff_ids:\n",
    "    # Conservative action: set those affiliate_id to NaN (we don't invent affiliate rows)\n",
    "    df_players_clean.loc[df_players_clean['affiliate_id'].isin(list(missing_aff_ids)), 'affiliate_id'] = pd.NA\n",
    "    # record in exceptions\n",
    "    rec = df_players_clean[df_players_clean['affiliate_id'].isna()].copy()\n",
    "    rec['reason'] = 'player_affiliate_missing_after_validation'\n",
    "    exceptions.append(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c01d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes after cleaning\n",
      "players: (10, 6)\n",
      "affiliates: (10, 4)\n",
      "transactions: (3, 5)\n",
      "\n",
      "Exceptions summary (counts by reason):\n",
      "reason\n",
      "tx_before_player_creation    6\n",
      "duplicate_player_id          2\n",
      "tx_by_unkyc_player           2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final checks and write cleaned copies\n",
    "\n",
    "# Ensure transactions' player_id refers to an actual player (remove any remaining or record)\n",
    "tx_missing_players = df_transactions_clean[~df_transactions_clean['player_id'].isin(df_players_clean['id'])]\n",
    "if not tx_missing_players.empty:\n",
    "    tx_missing_players['reason'] = 'tx_post_clean_missing_player'\n",
    "    exceptions.append(tx_missing_players)\n",
    "    df_transactions_clean = df_transactions_clean[df_transactions_clean['player_id'].isin(df_players_clean['id'])]\n",
    "\n",
    "# Ensure amounts > 0\n",
    "bad_amounts = df_transactions_clean[df_transactions_clean['amount'] <= 0]\n",
    "if not bad_amounts.empty:\n",
    "    bad_amounts['reason'] = 'non_positive_amount'\n",
    "    exceptions.append(bad_amounts)\n",
    "    df_transactions_clean = df_transactions_clean[df_transactions_clean['amount'] > 0]\n",
    "\n",
    "# summary\n",
    "print(\"Final shapes after cleaning\")\n",
    "print(\"players:\", df_players_clean.shape)\n",
    "print(\"affiliates:\", df_affiliates_clean.shape)\n",
    "print(\"transactions:\", df_transactions_clean.shape)\n",
    "\n",
    "# create df_exceptions if any\n",
    "if exceptions:\n",
    "    df_exceptions = pd.concat(exceptions, ignore_index=True, sort=False)\n",
    "else:\n",
    "    df_exceptions = pd.DataFrame(columns=['reason'])\n",
    "\n",
    "# Show top violations by reason\n",
    "if not df_exceptions.empty:\n",
    "    print(\"\\nExceptions summary (counts by reason):\")\n",
    "    print(df_exceptions['reason'].value_counts())\n",
    "else:\n",
    "    print(\"No exceptions recorded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70274ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote cleaned data and exceptions to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Write CSVs for inspection\n",
    "\n",
    "df_players_clean.to_csv(f\"{ROOT}/players_cleaned_from_notebook.csv\", index=False)\n",
    "df_affiliates_clean.to_csv(f\"{ROOT}/affiliates_cleaned_from_notebook.csv\", index=False)\n",
    "df_transactions_clean.to_csv(f\"{ROOT}/transactions_cleaned_from_notebook.csv\", index=False)\n",
    "df_exceptions.to_csv(f\"{ROOT}/exceptions_from_notebook.csv\", index=False)\n",
    "\n",
    "print(\"Wrote cleaned data and exceptions to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93075d96",
   "metadata": {},
   "source": [
    "### Task 2 - Write a Python script that extends the sample data for these tables according to the provided schema to 1000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3b1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python script part_1_task_2__expand_clean_data.py in the /scripts directory "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
